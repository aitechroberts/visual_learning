\documentclass[11pt,addpoints,answers]{exam}
\usepackage[margin=1in]{geometry}
\usepackage{amsmath, amsfonts}
\usepackage{enumerate}
\usepackage{graphicx}
\usepackage{titling}
\usepackage{url}
\usepackage{xfrac}
\usepackage{geometry}
\usepackage{graphicx}
\usepackage{natbib}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{amsthm}
\usepackage{paralist}
\usepackage{epstopdf}
\usepackage{tabularx}
\usepackage{longtable}
\usepackage{multirow}
\usepackage{multicol}
\usepackage[colorlinks=true,urlcolor=blue]{hyperref}
\usepackage{fancyvrb}
\usepackage{algorithm}
\usepackage{algorithmic}
\usepackage{float}
\usepackage{paralist}
\usepackage[svgname]{xcolor}
\usepackage{enumerate}
\usepackage{array}
\usepackage{times}
\usepackage{url}
\usepackage{comment}
\usepackage{environ}
\usepackage{times}
\usepackage{textcomp}
\usepackage{caption}
\usepackage[colorlinks=true,urlcolor=blue]{hyperref}
\usepackage{listings}
\usepackage{parskip} % For NIPS style paragraphs.
\usepackage[compact]{titlesec} % Less whitespace around titles
\usepackage[inline]{enumitem} % For inline enumerate* and itemize*
\usepackage{datetime}
\usepackage{comment}
% \usepackage{minted}
\usepackage{lastpage}
\usepackage{color}
\usepackage{xcolor}
\usepackage{listings}
\usepackage{tikz}
\usetikzlibrary{shapes,decorations,bayesnet}
%\usepackage{framed}
\usepackage{graphicx}
\usepackage{booktabs}
\usepackage{cprotect}
\usepackage{xcolor}
\usepackage{verbatimbox}
\usepackage[many]{tcolorbox}
\usepackage{cancel}
\usepackage{wasysym}
\usepackage{mdframed}
\usepackage{subcaption}
\usetikzlibrary{shapes.geometric}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Formatting for \CorrectChoice of "exam" %
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\CorrectChoiceEmphasis{}
\checkedchar{\blackcircle}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Better numbering                        %
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\numberwithin{equation}{section} % Number equations within sections (i.e. 1.1, 1.2, 2.1, 2.2 instead of 1, 2, 3, 4)
\numberwithin{figure}{section} % Number figures within sections (i.e. 1.1, 1.2, 2.1, 2.2 instead of 1, 2, 3, 4)
\numberwithin{table}{section} % Number tables within sections (i.e. 1.1, 1.2, 2.1, 2.2 instead of 1, 2, 3, 4)


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Common Math Commands                    %
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\input{mathabbreviations.tex}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Code highlighting with listings         %
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\definecolor{bluekeywords}{rgb}{0.13,0.13,1}
\definecolor{greencomments}{rgb}{0,0.5,0}
\definecolor{redstrings}{rgb}{0.9,0,0}
\definecolor{light-gray}{gray}{0.95}

\newcommand{\MYhref}[3][blue]{\href{#2}{\color{#1}{#3}}}%

\definecolor{dkgreen}{rgb}{0,0.6,0}
\definecolor{gray}{rgb}{0.5,0.5,0.5}
\definecolor{mauve}{rgb}{0.58,0,0.82}

\lstdefinelanguage{Shell}{
  keywords={tar, cd, make},
  %keywordstyle=\color{bluekeywords}\bfseries,
  alsoletter={+},
  ndkeywords={python, py, javac, java, gcc, c, g++, cpp, .txt, octave, m, .tar},
  %ndkeywordstyle=\color{bluekeywords}\bfseries,
  identifierstyle=\color{black},
  sensitive=false,
  comment=[l]{//},
  morecomment=[s]{/*}{*/},
  commentstyle=\color{purple}\ttfamily,
  stringstyle=\color{red}\ttfamily,
  morestring=[b]',
  morestring=[b]",
  backgroundcolor = \color{light-gray}
}

\lstset{columns=fixed, basicstyle=\ttfamily,
    backgroundcolor=\color{light-gray},xleftmargin=0.5cm,frame=tlbr,framesep=4pt,framerule=0pt}



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Custom box for highlights               %
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% Define box and box title style
\tikzstyle{mybox} = [fill=blue!10, very thick,
    rectangle, rounded corners, inner sep=1em, inner ysep=1em]

% \newcommand{\notebox}[1]{
% \begin{tikzpicture}
% \node [mybox] (box){%
%     \begin{minipage}{\textwidth}
%     #1
%     \end{minipage}
% };
% \end{tikzpicture}%
% }

\NewEnviron{notebox}{
\begin{tikzpicture}
\node [mybox] (box){
    \begin{minipage}{\textwidth}
        \BODY
    \end{minipage}
};
\end{tikzpicture}
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Commands showing / hiding solutions     %
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%% To HIDE SOLUTIONS (to post at the website for students), set this value to 0: \def\issoln{0}
\def\issoln{0}
% Some commands to allow solutions to be embedded in the assignment file.
\ifcsname issoln\endcsname \else \def\issoln{0} \fi
% Default to an empty solutions environ.
\NewEnviron{soln}{}{}
% Default to an empty qauthor environ.
\NewEnviron{qauthor}{}{}
% Default to visible (but empty) solution box.
\newtcolorbox[]{studentsolution}[1][]{%
    breakable,
    enhanced,
    colback=white,
    title=Solution,
    #1
}

\if\issoln 1
% Otherwise, include solutions as below.
\RenewEnviron{soln}{
    \leavevmode\color{red}\ignorespaces
    \textbf{Solution} \BODY
}{}
\fi

\if\issoln 1
% Otherwise, include solutions as below.
\RenewEnviron{solution}{}
\fi

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Commands for customizing the assignment %
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\newcommand{\courseNum}{\href{https://visual-learning.cs.cmu.edu/}{16824}}
\newcommand{\courseName}{\href{https://visual-learning.cs.cmu.edu/}{Visual Learning and Recognition}}
\newcommand{\courseSem}{\href{https://visual-learning.cs.cmu.edu/}{Fall 2025}}
\newcommand{\courseUrl}{\url{https://piazza.com/cmu/fall2025/16824/home}}
\newcommand{\hwNum}{Homework 3}
\newcommand{\hwTopic}{Transformers}
\newcommand{\hwName}{\hwNum: \hwTopic}
\newcommand{\outDate}{Fri, 24th Oct 2025}
\newcommand{\dueDate}{11:59 PM ET, Thu, 13th Nov 2025}
\newcommand{\instructorName}{Jun-Yan Zhu}
\newcommand{\taNames}{Ananya Bal, Zhixuan Liu, Eungyeup Kim, Jay Karhade}

%\pagestyle{fancyplain}
\lhead{\hwName}
\rhead{\courseNum}
\cfoot{\thepage{} of \numpages{}}

\title{\textsc{\hwName}} % Title


\author{}

\date{}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Useful commands for typesetting the questions %
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\newcommand \expect {\mathbb{E}}
\newcommand \mle [1]{{\hat #1}^{\rm MLE}}
\newcommand \map [1]{{\hat #1}^{\rm MAP}}
\newcommand \argmax {\operatorname*{argmax}}
\newcommand \argmin {\operatorname*{argmin}}
\newcommand \code [1]{{\tt #1}}
\newcommand \datacount [1]{\#\{#1\}}
\newcommand \ind [1]{\mathbb{I}\{#1\}}

\newcommand{\blackcircle}{\tikz\draw[black,fill=black] (0,0) circle (1ex);}
\renewcommand{\circle}{\tikz\draw[black] (0,0) circle (1ex);}

\newcommand{\pts}[1]{\textbf{[#1 pts]}}

%%%%%%%%%%%%%%%%%%%%%%%%%%
% Document configuration %
%%%%%%%%%%%%%%%%%%%%%%%%%%

% Don't display a date in the title and remove the white space
\predate{}
\postdate{}
\date{}

%%%%%%%%%%%%%%%%%%
% Begin Document %
%%%%%%%%%%%%%%%%%%


\begin{document}

\section*{}
\begin{center}
  \textsc{\LARGE \hwNum} \\
%   \textsc{\LARGE \hwTopic\footnote{Compiled on \today{} at \currenttime{}}} \\
  \vspace{1em}
  \textsc{\large \courseNum{} \courseName{} (\courseSem)} \\
  %\vspace{0.25em}
  \courseUrl\\
  \vspace{1em}
  RELEASED: \outDate \\
  DUE: \dueDate \\
  Instructor: \instructorName \\
  TAs: \taNames
\end{center}

\section*{START HERE: Instructions}
\begin{itemize}
\item \textbf{Collaboration policy:} All are encouraged to work together BUT you must do your own work (code and write up). If you work with someone, please include their name in your write-up and cite any code that has been discussed. If we find highly identical write-ups or code or lack of proper accreditation of collaborators, we will take action according to strict university policies. See the \href{hhttps://www.cmu.edu/policies/student-and-student-life/academic-integrity.html}{Academic Integrity Section} detailed in the initial lecture for more information.

\item\textbf{Late Submission Policy:} There are a \textbf{total of 5} late days across all homework submissions. Submissions that use additional late days will incur a 10\% penalty per late day.

\item\textbf{Submitting your work:}

\begin{itemize}

\item We will be using Gradescope (\url{https://gradescope.com/}) to submit the Problem Sets. Please use the provided template only. You do \textbf{not} need any additional packages and using them is \textbf{strongly discouraged}. Submissions must be written in LaTeX. All submissions not adhering to the template will not be graded and receive a zero. 
\item \textbf{Deliverables:} Please submit all the \texttt{.py} files. Add all relevant plots and text answers in the boxes provided in this file. To include plots you can simply modify the already provided latex code. Submit the compiled \texttt{.pdf} report as well.
\end{itemize}
\end{itemize}
\emph{NOTE: Partial points will be given for implementing parts of the homework even if you don't get the mentioned accuracy as long as you include partial results in this pdf.}
\clearpage

\section{Image Captioning with Transformers (75 points)}



We will be implementing the different pieces of a Transformer decoder (\href{https://arxiv.org/pdf/1706.03762.pdf}{Transformers}), and train it for image captioning on a subset of the \href{https://cocodataset.org/#home}{COCO dataset}. 
\begin{itemize}
    \item \textbf{Setup:} Run the following command to extract COCO data, in the \texttt{transformer\_captioning/datasets} folder : \texttt{./get\_coco\_captioning.sh}
    %: \\ 
    % \texttt{get_coco_captioningsh}
\item \textbf{Question:} Follow the instructions in the \texttt{README.md} file in the \texttt{transformer\_captioning} folder to complete the implementation of the transformer decoder.
\item \textbf{Deliverables:} After implementing all parts, use run.py for training the full model. The code will log plots to \texttt{plots}. Extract plots and paste them into the appropriate section below. 

\item \textbf{Expected results:}
    These are expected training losses after 100 epochs. Do not change the seed in run.py.
    \begin{itemize}
        \item 2-heads, 2-layers, lr 1e-4: Final loss $\leq$ 1 
        \item 4-heads, 6-layers, lr 1e-4: Final loss $\leq$ 0.3 
        \item 4-heads, 6-layers, lr 1e-3: Final loss $\leq$ 0.05
    \end{itemize}
\end{itemize}

\begin{questions}
\question Paste training loss plots for each of the three hyper-param configs
\\
2-heads-2-layers-lr-1e-4: \textbf{loss: 0.778242} \\
4-heads-6-layers-lr-1e-4: \textbf{loss: 0.258864} \\
4-heads-6-layers-lr-1e-3: \textbf{loss: 0.049734} 
\begin{figure}[H]
    \centering
    % TODO: put your plot here.
    \begin{subfigure}[b]{0.32\linewidth}
        \includegraphics[width=\linewidth]{transformer_captioning/2head2layer/case1_loss_out.png}
        \caption{2-heads-2-layers-lre-4}
    \end{subfigure}
    \begin{subfigure}[b]{0.32\linewidth}
        \includegraphics[width=\linewidth]{transformer_captioning/4head6layerlow/case2_loss_out.png}
        \caption{4-heads-6-layers-lre-4}
    \end{subfigure}
    \begin{subfigure}[b]{0.32\linewidth}
        \includegraphics[width=\linewidth]{transformer_captioning/4head6layerhigh/case3_loss_out.png}
        \caption{4-heads-6-layers-lre-3}
    \end{subfigure}
    
\end{figure}
\question Paste any three generated captioning samples from the training set with the three different settings. The provided code creates these plots at the end of training.
\\
\begin{figure}[H]
    \centering
    \begin{subfigure}[b]{0.32\linewidth}
        \includegraphics[width=\linewidth]{transformer_captioning/2head2layer/case1_train_2.png}
        \caption{Sample1: 2-heads-2-layers-lre-4}
    \end{subfigure}
    \begin{subfigure}[b]{0.32\linewidth}
        \includegraphics[width=\linewidth]{transformer_captioning/4head6layerlow/case2_train_1.png}
        \caption{Sample2:4-heads-6-layers-lre-4}
    \end{subfigure}
    \begin{subfigure}[b]{0.32\linewidth}
        \includegraphics[width=\linewidth]{transformer_captioning/4head6layerhigh/case3_train_4.png}
        \caption{Sample3:4-heads-6-layers-lre-3}
    \end{subfigure}
\end{figure}

\item Based on the observations of the three different settings, What would you change in the training procedure to get better validation performance? Why tweaking these hyper-parameters will lead to better performances?

\begin{solution}
\\ 
Based on the above plots, we can see that the 4-heads-6-layers-lr-1e-3 configuration rapidly converges to a lower loss than the first two experiments, but fails to consistently converge well afterward. To fix this, focusing only on the hyperparameter part of the training, I would follow two main improvements: [1] Decrease the learning rate with an increased number of epochs and a learning rate scheduler. 1e-3 is clearly too aggressive as you can see in the oscillations. One could possibly add a warmup in this stage if the lr is low enough, but with so little data, I believe that is not required. [2] With the mentioned overfitting, I would attempt to alleviate overfitting with the following: I would include a weight decay in the optimizer as well as increased dropout and an increased batch size. These should sufficiently include regularization to improve training on this dataset though precise values would need experimentation to find the right fit.
\end{solution}

\item Experiment by replacing the activations in your transformer implementation with more modern activations such as SwiGLU. Paste the training loss plot below. Then describe the loss function used and performance changes observed.

\begin{figure}[H]
    \centering
    \begin{subfigure}[b]{0.32\linewidth}
        \includegraphics[width=\linewidth]{transformer_captioning/swiglu_decoder/case5_loss_out.png}
        \caption{Sample: SwiGLU training}
    \end{subfigure}
    \begin{subfigure}[b]{0.32\linewidth}
        \includegraphics[width=\linewidth]{transformer_captioning/singlu_decoder/case3_loss_out.png}
        \caption{Sample: SinGLU training}
    \end{subfigure}
\end{figure}
\begin{figure}[H]
    \centering
    \begin{subfigure}[b]{0.32\linewidth}
        \includegraphics[width=\linewidth]{transformer_captioning/swiglu_lr17e4/case5_loss_out.png}
        \caption{Sample: SwiGLU LR: 1.7e-4}
    \end{subfigure}
    \begin{subfigure}[b]{0.32\linewidth}
        \includegraphics[width=\linewidth]{transformer_captioning/singlu_lr17e4/case5_loss_out.png}
        \caption{Sample: SinGLU LR: 1.7e-4}
    \end{subfigure}
\end{figure}

\begin{solution}
\\ 
I attempted both SwiGLU as requested and a supposed improvement over SwiGLU called SinGLU, a Sin-based GLU activation function proposed in this paper: “Improving Vision Transformers with Novel GLU-Type Nonlinearities”. I also did this across the first final learning rate above of 1e-3 and a smaller, but still slightly larger learning rate of 1.7e-4 to benefit from some slightly faster convergence than 1e-4. As you can see, the Gated Linear Unit activation functions prefer a lower learning rate to provide improvements over RELU. As for the loss, I did not make a change from Cross-Entropy loss as we did not change the expected output here, and the activation function change does not affect that. \\
SwiGLU training loss: \textbf{loss: 0.096604}, SinGLU training loss: \textbf{loss: 0.092521} \\
SwiGLU LR: 1.7e-4 training loss: \textbf{loss: 0.034074}, SinGLU LR: 1.7e-4 training loss: \textbf{loss: 0.052016}, (This one actually got down to a loss of 0.015 at epoch 90 but jumped back up at the end to lose to SwiGLU, so a scheduler and some finetuning would be interesting.)
\end{solution}

\end{questions}
\clearpage

\section{Classification with Vision Transformers (25 points)}



We will use the transformer you implemented in the previous part to implement a Vision Transformer (\href{https://arxiv.org/abs/2010.11929}{ViT}), for classification on CIFAR10. 

\begin{itemize}
    \item \textbf{Question:} Follow the instructions in the \texttt{README.md} file in the \texttt{vit\_classification} folder. You are encouraged to resuse code from the previous question. 
    \item \textbf{Deliverables:} Run training using \texttt{run.py} for training the full model. The code will log plots \texttt{acc\_out.png} (train and test accuracy) and \texttt{loss\_out.png} (train loss). 
    \item \textbf{Expected Results:} After 100 epochs, test accuracy should be around $65\%$, train accuracy should be $\approx 100\%$, and training loss $\leq 0.3$. 
\end{itemize}

\begin{figure}[H]
    \centering
    \begin{subfigure}[b]{0.32\linewidth}
        \includegraphics[width=\linewidth]{vit_classification/acc_out.png}
        \caption{Train/test accuracy}
    \end{subfigure}
    \begin{subfigure}[b]{0.32\linewidth}
        \includegraphics[width=\linewidth]{vit_classification/loss_out.png}
        \caption{Training loss}
    \end{subfigure}
\end{figure}


\begin{solution}
\\ 
\textbf{SwiGLU Implementation}
Test Accuracy: \textbf{0.683700}

Train Accuracy: \textbf{1.000000 [Achieved from epoch 97 onward]}

Training Loss: \textbf{loss: 0.025288}
% YOU ANSWER HERE
\end{solution}

\clearpage

\textbf{Collaboration Survey} Please answer the following:

\begin{enumerate}
    \item Did you receive any help whatsoever from anyone in solving this assignment?
    \begin{checkboxes}
     \choice Yes
     \choice No
    \end{checkboxes}
    \begin{itemize}
        \item If you answered `Yes', give full details:
        \item (e.g. “Jane Doe explained to me what is asked in Question 3.4”)
    \end{itemize}

    \begin{tcolorbox}[fit,height=3cm,blank, borderline={1pt}{-2pt},nobeforeafter]
    %Input your solution here.  Do not change any of the specifications of this solution box.
    \end{tcolorbox}

    \item Did you give any help whatsoever to anyone in solving this assignment?
    \begin{checkboxes}
     \choice Yes
     \choice No\
    \end{checkboxes}
    \begin{itemize}
        \item If you answered `Yes', give full details:
        \item (e.g. “I pointed Joe Smith to section 2.3 since he didn’t know how to proceed with Question 2”)
    \end{itemize}

    \begin{tcolorbox}[fit,height=3cm,blank, borderline={1pt}{-2pt},nobeforeafter]
    %Input your solution here.  Do not change any of the specifications of this solution box.
    \end{tcolorbox}

    \item Note that copying code or writeup even from a collaborator or anywhere on the internet violates the \href{hhttps://www.cmu.edu/policies/student-and-student-life/academic-integrity.html}{Academic Integrity Code of Conduct}.
\end{enumerate}

\end{document}